{
 "cells": [
  {
   "cell_type": "code",
   "id": "6f85a72b214b5242",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T22:32:16.924682Z",
     "start_time": "2024-06-05T22:32:13.738850Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f85a72b214b5242",
    "outputId": "6ad5e3ee-f809-46c5-f1c4-5dff68c2d171"
   },
   "source": [
    "#temporary cell - for testing; after incorporating into the main code, it will not be used\n",
    "#Agent class will use Persona class and will supply ai client object to it\n",
    "\n",
    "!pip install openai\n",
    "from openai import OpenAI\n",
    "from google.colab import userdata\n",
    "secret_key = userdata.get('openai_key')\n",
    "client = OpenAI(api_key=secret_key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.31.1-py3-none-any.whl (324 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m324.1/324.1 kB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.6/75.6 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.9/77.9 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "Installing collected packages: h11, httpcore, httpx, openai\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.31.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T22:32:24.878248Z",
     "start_time": "2024-06-05T22:32:21.242679Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "eb067f08-f77a-449a-f848-d6a2a139276d"
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class Persona:\n",
    "    \"\"\"\n",
    "    Class Persona constructs a persona based on a given raw string input with specific model.\n",
    "\n",
    "    Attributes:\n",
    "    raw_string : str\n",
    "        A raw string input defining persona attributes\n",
    "    model : str\n",
    "        An AI model used to process the persona attributes\n",
    "    persona_desc : str\n",
    "        Description of persona obtained from raw string, processed by an AI model\n",
    "    \"\"\"\n",
    "    def __init__(self, aiclient,raw_string, model_name):\n",
    "        self.raw_string = raw_string\n",
    "        self.model = model_name\n",
    "        self.aiclient = aiclient\n",
    "        if raw_string:\n",
    "            self.persona_desc = self.persona_from_rawstring(raw_string, model_name)\n",
    "\n",
    "    def persona_from_rawstring(self, raw_string, modelname):\n",
    "        \"\"\"\n",
    "        Method to retrieve and format the persona description from the raw string input provided using OpenAI's language model.\n",
    "\n",
    "        Parameters:\n",
    "        raw_string : str\n",
    "            string input that describes the persona\n",
    "        modelname : str\n",
    "            name of AI model used for processing\n",
    "\n",
    "        Returns:\n",
    "        str\n",
    "            A formatted persona_description\n",
    "        \"\"\"\n",
    "        demographic = []\n",
    "        questions = self.get_questions(demographic)\n",
    "        prompt = f\" {raw_string} \\nExtract information from the text provided, do not use any outside information. What is the person's: \\n{questions} \"\n",
    "\n",
    "        response = self.aiclient.chat.completions.create(\n",
    "            model=modelname,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "                {\"role\": \"user\", \"content\": f\" {prompt} \"}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content\n",
    "        return self.format_persona(result, demographic)\n",
    "\n",
    "    def get_questions(self, arr_info):\n",
    "        \"\"\"\n",
    "        Method to retrieve demographic questions from file.\n",
    "\n",
    "        Parameters:\n",
    "        arr_info : list\n",
    "            An array used to store info from the file\n",
    "\n",
    "        Returns:\n",
    "        str\n",
    "            A string of questions retrieved from the file\n",
    "        \"\"\"\n",
    "\n",
    "        with open('demographic_questions.txt', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        questions = \"\"\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            parts = line.split('^')\n",
    "            questions += f\"^ {parts[0]}? {parts[1]} Do not answer this question if not mentioned , do not assume\\n\"\n",
    "            arr_info.append(parts)\n",
    "        return questions\n",
    "\n",
    "    def format_persona(self, demographic_info_json, arrdemographic):\n",
    "\n",
    "        import json\n",
    "        demographic_info = json.loads(demographic_info_json)\n",
    "\n",
    "        persona_desc = ''\n",
    "\n",
    "        for key, value in demographic_info.items():\n",
    "            for i in range(len(arrdemographic)):\n",
    "                if arrdemographic[i][0].strip() == key:\n",
    "                    if value and value not in ['not provided', 'not mentioned']:\n",
    "                        persona_desc += arrdemographic[i][2] + \" \" + str(value) + \". \"\n",
    "                    break\n",
    "        return persona_desc\n",
    "\n",
    "\n",
    "raw_str = \"a 20 year old man from Ohio who is an independent with a graduate degree\"\n",
    "\n",
    "persona1 = Persona(client,raw_str, \"gpt-3.5-turbo-0125\")\n",
    "persona2 = Persona(client, raw_str, \"gpt-4-1106-preview\")\n",
    "\n",
    "print('gpt-3.5-turbo-0125:', persona1.persona_desc)\n",
    "print('gpt-4-1106-preview:', persona2.persona_desc)\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gpt-3.5-turbo-0125: your age is 20. your gender is male. your education is graduate degree. politically, you identify as a independent. you live in Ohio. \n",
      "gpt-4-1106-preview: your age is 20. your gender is male. your education is graduate degree. politically, you identify as a independent. you live in Ohio. \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T22:07:07.205599Z",
     "start_time": "2024-06-05T22:07:07.200100Z"
    },
    "id": "5cdc7251e65599b4"
   },
   "cell_type": "code",
   "source": [],
   "id": "5cdc7251e65599b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "187f65322031b1ea"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "187f65322031b1ea"
  },
  {
   "metadata": {
    "id": "d2008c3ecd0a881b"
   },
   "cell_type": "markdown",
   "source": [],
   "id": "d2008c3ecd0a881b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
